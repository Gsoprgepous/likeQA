# -*- coding: utf-8 -*-
"""Копия блокнота "Untitled0.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PFjPOS1MdO5RivqtGBqv-Lj5rPn-U76l
"""

import pandas as pd
import re
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.model_selection import train_test_split
from transformers import BertTokenizer
from google.colab import files
import tensorflow as tf
from transformers import TFBertModel
from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score

# 1. Загрузка файла
upload = files.upload()
file_path = '/content/trainnn.xlsx'

# 2. Чтение файла
try:
    data = pd.read_excel(file_path, engine='openpyxl')
except FileNotFoundError:
    raise FileNotFoundError(f"Файл {file_path} не найден.")

# Убедитесь, что столбцы 'text' и 'tags' существуют
if 'text' not in data.columns:
    raise KeyError("Столбец 'text' не найден в DataFrame. Проверьте названия столбцов.")
if 'tags' not in data.columns:
    raise KeyError("Столбец 'tags' не найден в DataFrame. Проверьте названия столбцов.")

# 4. Предобработка текста
def clean_text(text):
    if isinstance(text, str):  # Проверка, что text — это строка
        text = re.sub(r'[^a-zA-Z0-9\s]', '', text)  # Удаляем ненужные символы
        text = text.lower()  # Приводим к нижнему регистру
        return text
    return ''  # Возвращаем пустую строку для NaN или других типов

data['cleaned_text'] = data['text'].apply(clean_text)

# 5. Токенизация и создание меток
def process_tags(tags):
    if isinstance(tags, str):
        return tags.split(',')
    return []  # Возвращаем пустой список для NaN или других типов

data['processed_tags'] = data['tags'].apply(process_tags)

mlb = MultiLabelBinarizer()
y = mlb.fit_transform(data['processed_tags'])

X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], y, test_size=0.2, random_state=42)

# 6. Подготовка BERT-токенизатора
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize(texts):
    return tokenizer(
        texts.tolist(),
        max_length=128,
        padding=True,
        truncation=True,
        return_tensors='tf'
    )

train_encodings = tokenize(X_train)
test_encodings = tokenize(X_test)

# 7. Создание модели с дополнительным слоем
class BertClassifier(tf.keras.Model):
    def __init__(self):
        super(BertClassifier, self).__init__()
        self.bert = TFBertModel.from_pretrained('bert-base-uncased')
        self.dropout = tf.keras.layers.Dropout(0.3)
        self.classifier = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(len(mlb.classes_), activation='sigmoid')
        ])

    def call(self, inputs):
        outputs = self.bert(inputs)[1]  # Получаем выходные данные [CLS]
        outputs = self.dropout(outputs)
        return self.classifier(outputs)

model = BertClassifier()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 8. Обучение модели с увеличением эпох
model.fit(
    train_encodings['input_ids'], y_train,
    epochs=12,  # Увеличение числа эпох
    batch_size=2,
    validation_split=0.5
)

# 9. Оценка модели
y_pred = model.predict(test_encodings['input_ids'])
y_pred_bin = (y_pred > 0.5).astype(int)

# 10. Метрики
print("F1 Score:", f1_score(y_test, y_pred_bin, average='macro'))
print("Precision:", precision_score(y_test, y_pred_bin, average='macro'))
print("Recall:", recall_score(y_test, y_pred_bin, average='macro'))

# 9. Оценка модели с изменением порога
threshold = 0.8  # Попробуйте изменить порог
y_pred_bin = (y_pred > threshold).astype(int)

# 10. Метрики
print("F1 Score:", f1_score(y_test, y_pred_bin, average='macro'))
print("Precision:", precision_score(y_test, y_pred_bin, average='macro', zero_division=1))
print("Recall:", recall_score(y_test, y_pred_bin, average='macro', zero_division=1))

# 11. Вычисление точности
target_true = y_test
target_pred = y_pred_bin
print("Accuracy Score:", accuracy_score(target_true, target_pred))

# 12. Подготовка sample_submission.csv
sample_submission = pd.DataFrame(data={'ID': data.loc[X_test.index, 'ID']})  # Предполагается, что есть столбец 'ID'
sample_submission = pd.concat([sample_submission, pd.DataFrame(y_pred_bin, columns=mlb.classes_)], axis=1)

# Сохранение в CSV файл
sample_submission.to_csv('sample_submission.csv', index=False)
files.download('sample_submission.csv')